{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01c58b18-e584-4fa2-bfed-f4e1be7a9753",
   "metadata": {},
   "source": [
    "## 질문zip\n",
    "---\n",
    "- sns.factorplot('Pclass','Survived',hue='Sex',data=data) 에서 factorplot을 더이상 지원하지 않아 나는 catplot으로 하였는데 다른 그루들은 어떻게 표현했는 지 궁금하다.\n",
    "- plt.close(2) 이걸 하면 catplot 그래프 출력이 안 됨\n",
    "- familsize 부분에서 혼자 있는 것이 **Sex**나 **Pclass**와 상관없이 해롭다는 것을 알 수 있다.  이해가 안 된다.\n",
    "- KNN출력결과가 다르게 나오는데 다른 그루들은 어떻게 나오는지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc647be2-58c2-44c8-b2e1-af6fe97f3fa7",
   "metadata": {},
   "source": [
    "## Part1: Exploratory Data Analysis(EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507f903f-2c69-4e30-aad2-f4c3dc53413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5a8fed-888f-42ac-88f1-408f7850e8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1de94a-a37a-4ceb-b097-75e1fad8321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56523b2-6d0b-4094-aafd-b67089dfcd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 제거\n",
    "data.isna().sum() # isnull() 과 같은 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebf47fe-dc32-404e-8e83-c016b3d76dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age, cabin, embarked 가 null값을 포함하므로 이를 수정.\n",
    "# 수정하는 코드 어디?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ceaef7-46d6-4355-a7a9-d36b02cab145",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54387b39-ff68-4fd5-a239-ba824262e708",
   "metadata": {},
   "source": [
    "## How many Survived??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37d8449-4188-48cd-ba12-ec3c20d5d525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib와 seaborn을 사용하여 Survived (생존 여부) 에 대한 시각화를 2가지 형태로 보여주는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9edaaa8-1b6e-45c1-98e3-9af2961cb7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(18,8))\n",
    "# f는 전체 객체, ax는 각 subplot의 축(ax)를 담은 리스트\n",
    "# 두 개의 그래프를 합치도록 subplots\n",
    "# 1행 2열 형태\n",
    "\n",
    "# 왼쪽: 파이 차트\n",
    "data['Survived'].value_counts().plot.pie(\n",
    "    explode=[0, 0.1], # 생존쪽을 약간 띄워서 \n",
    "    autopct='%.1f%%', # 소수점 첫째 자리까지 표시\n",
    "    ax=ax[0], # 첫 번째 ax 요소에 그리기\n",
    "    shadow=True # 그림자 가가\n",
    ")\n",
    "ax[0].set_title('Survived')\n",
    "ax[0].set_ylabel('')\n",
    "\n",
    "# 오른쪽: 막대 그래프\n",
    "sns.countplot(x='Survived', data=data, ax=ax[1])\n",
    "# countplot 범주형 데이터의 개수를 세어 막대 그래프로 시각화\n",
    "\n",
    "ax[1].set_title('Survived')\n",
    "\n",
    "f.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a2afbc-ebc0-4a33-b6ec-c7570872f525",
   "metadata": {},
   "source": [
    "%.1f%% 에서 %%를 두 번 사용하는 이유?  \n",
    "%자체도 출력하기 위함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b6b9c7-89e5-4965-b5b7-afbd8676a660",
   "metadata": {},
   "source": [
    "## Analysing The Features  \n",
    "### Sex--> Categorical Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aeebea-7557-490a-a570-26c9c159ed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['Sex', 'Survived'])['Survived'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a09441-a669-4622-aaf2-504179d97aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,2, figsize=(18,8))\n",
    "data[['Sex','Survived']].groupby(['Sex']).mean().plot.bar(ax=ax[0])\n",
    "ax[0].set_title('Survived vs Sex')\n",
    "\n",
    "sns.countplot(x='Sex',hue='Survived',data=data,ax=ax[1])\n",
    "# hue 색깔로 그룹을 나누는 기준\n",
    "ax[1].set_title('Sex: Survived vs Dead')\n",
    "\n",
    "f.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cb22bc-f511-4bee-80e2-d8079bf28e9a",
   "metadata": {},
   "source": [
    "✔️ countplot은 \"각 생존 여부에 대한 개수만 시각화\" 해줄 뿐, 전체 수는 따로 안 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b956a4-5067-4bbd-8174-b845c8051a3e",
   "metadata": {},
   "source": [
    "배에 탑승한 남성의 수가 여성보다 훨씬 많습니다.  \n",
    "그런데도 구조된 여성의 수는 남성보다 거의 두 배에 달한다.  \n",
    "여성의 생존률은 약 **75%**인 반면, 남성은 18~19% 정도이다.  \n",
    "  \n",
    "이건 모델링에 아주 중요한 특징(피처)처럼 보인다.  \n",
    "다른 피처들도 확인해보겠다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715ac69d-6738-4eff-a475-a9b8a5613037",
   "metadata": {},
   "source": [
    "## Pclass --> Ordinal Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895d7dc8-2ffe-4fdc-a26b-033ea79195aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data.Pclass, data.Survived, margins=True).style.background_gradient(cmap='summer_r')\n",
    "# margins = True 행과 열의 총합(All)을 같이 보여준다.\n",
    "# style.background_gradient DataFrame에 색상 그라디언트를 입혀서 숫자 크기를 직관적으로 보이게 해준다.\n",
    "# cmap='summer_r' 노랑~연두로 반대로 적용됨(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4251b426-267c-4a62-b52d-d56e3fcaca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,2,figsize=(18,8))\n",
    "data['Pclass'].value_counts().plot.bar(ax=ax[0])\n",
    "ax[0].set_title('Number of Passengers By Pclass')\n",
    "ax[0].set_ylabel('Count')\n",
    "\n",
    "sns.countplot(x='Pclass', hue='Survived', data=data, ax=ax[1])\n",
    "ax[1].set_title('Pclass: Survived vs Dead')\n",
    "\n",
    "f.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b8d599-2d91-4ca5-8b4a-80719314755b",
   "metadata": {},
   "source": [
    "🔍 인사이트  \n",
    "Pclass와 생존률 데이터를 보면, 1등석 승객의 생존률이 높고, 3등석은 낮은 경향이 뚜렷하게 나타난다.  \n",
    "\n",
    "따라서, 타이타닉 사고 당시 부유한 사람들이 구조 우선권을 부여받았고,  \n",
    "상류층의 생존율이 높았다는 사회적, 경제적 불평등을 반영하는 중요한 인사이트가 될 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b15bdc0-2854-4d15-95c7-143083742d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab([data.Sex, data.Survived], data.Pclass, margins=True).style.background_gradient(cmap='summer_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4057dc14-9476-4b39-befa-67dfc8ce247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.factorplot('Pclass','Survived',hue='Sex',data=data)\n",
    "# 더이상 factorplot을 지원하지 않아 catplot으로 표현\n",
    "\n",
    "sns.catplot(x='Pclass', y='Survived', hue='Sex', data=data, kind='point')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc12685b-28f1-4aeb-b4df-9a5babdba20b",
   "metadata": {},
   "source": [
    "🔍 인사이트  \n",
    "Pclass와 관계없이, 여성은 구조 시 우선권을 받았다는 것이 분명하다.  \n",
    "Pclass 1의 남성들조차 생존율이 매우 낮다.    \n",
    "Pclass도 중요한 특징인 것 같다.  \n",
    "성별과 Pclass가 구조 시 영향을 많이 받았다는 인사이트를 도출할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590c4dd2-6958-49ca-8e64-ead6696af1b5",
   "metadata": {},
   "source": [
    "## Age--> Continous Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743b97cc-54cd-4680-98fc-c5f50a2ca2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Oldest Passenger was of:',data['Age'].max(),'Years')\n",
    "print('Youngest Passenger was of:',data['Age'].min(),'Years')\n",
    "print('Average Age on the ship:',round(data['Age'].mean(),2),'Years') # 나이라서 소수점 둘째자리 까지 나오게 출력함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1df33b0-b31f-4c7f-9efe-8d89fa2f4ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,2, figsize=(18,8))\n",
    "sns.violinplot(x=\"Pclass\",y=\"Age\", hue=\"Survived\", data=data,ax=ax[0])\n",
    "ax[0].set_title('Pclass and Age vs Survived')\n",
    "ax[0].set_yticks(range(0,110,10)) # 110까지 10씩 증가 -> 100까지 출\n",
    "\n",
    "sns.violinplot(x=\"Sex\",y=\"Age\", hue=\"Survived\", data=data,split=True,ax=ax[1])\n",
    "ax[1].set_title('Sex and Age vs Survived')\n",
    "ax[1].set_yticks(range(0,110,10))\n",
    "\n",
    "f.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c141b7-c6ee-425c-8d82-e289601e4877",
   "metadata": {},
   "source": [
    "🔍 인사이트  \n",
    "나이가 어린 어린이들은 Pclass와 관계없이 생존 확률이 높다.  \n",
    "어린이를 먼저 구조했을 가능성이 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07074eed-7d68-4c3e-9ca0-fa7fa03d7116",
   "metadata": {},
   "source": [
    "Age 컬럼에는 총 177개의 결측치가 존재하며, 단순히 전체 평균으로 대체하는 방식은 부적절할 수 있다.  \n",
    "예를 들어, 어린이에게 전체 평균 나이인 29세를 넣는 것은 비현실적이다.  \n",
    "  \n",
    "이를 보완하기 위해 Name 컬럼을 활용한 방법이 제안된다.  \n",
    "Name에는 \"Mr\", \"Mrs\", \"Miss\", \"Master\" 등 호칭(title)이 포함되어 있어 승객의 성별과 대략적인 나이대를 유추할 수 있다.  \n",
    "- \"Mr\"는 보통 성인 남성\n",
    "- \"Mrs\"는 기혼 여성\n",
    "- \"Miss\"는 미혼 여성 또는 어린 소녀\n",
    "- \"Master\"는 어린 남자아이를 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ff296f-3666-4ce4-aa5e-2e25cdd9f3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Initial']=0\n",
    "for i in data:\n",
    "    data['Initial']=data.Name.str.extract('([A-Za-z]+)\\.') #lets extract the Salutations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e751f16-5185-4c28-9ac3-1f08f1ca546f",
   "metadata": {},
   "source": [
    "정규표현식 '([A-Za-z]+)\\.' 의미  \n",
    "(...): 괄호 안은 추출 대상 즉, 이 안에 해당되는 문자열을 뽑겠다는 뜻이다.  \n",
    "  \n",
    "`[A-Za-z]`: 대문자 AZ, 소문자 az 중 하나의 문자를 의미한다.  \n",
    "`+`: 앞의 [A-Za-z]가 1개 이상 반복된다는 뜻이다.  \n",
    "`\\.`: .은 원래 정규식에서 \"모든 문자\"를 뜻하는 특수문자라서, 진짜 마침표(.)를 의미하려면 `\\.`처럼 백슬래시로 이스케이프해야 한다.  \n",
    "- \"Smith, Mr. John\" → 'Mr'\n",
    "- \"Brown, Mrs. Clara\" → 'Mrs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2865d9f2-f7cd-4194-a1c6-913e1e3a73e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Initial.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad809da0-c31d-4e38-bded-8b2d2d96d98d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(data.Initial,data.Sex).T.style.background_gradient(cmap='summer_r')\n",
    "# .T 행과 열을 바꿔주는 역할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e9affb-6e34-4bd7-bbb1-79fe6464e2e8",
   "metadata": {},
   "source": [
    "replace함수를 배울 때 딕셔너리 형식으로 배워서 리스트 형식의 변환에 대해 알아보았다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf49554-b5e4-4f36-978d-fe7188e4960b",
   "metadata": {},
   "source": [
    "✨ Tip  \n",
    "- 리스트 방식  \n",
    "→ 바꿀 값이 많고, 1:1 매칭이 깔끔하게 될 때  \n",
    "→ 예: 호칭이나 라벨 등 규칙적으로 치환할 때  \n",
    "→ ['A', 'B', 'C'], ['X', 'Y', 'Z']  \n",
    "  \n",
    "- 딕셔너리 방식  \n",
    "→ 바꿀 값이 적고, 읽기 쉽게 표현하고 싶을 때  \n",
    "→ 예: 몇 개만 특정 값으로 바꿔줄 때  \n",
    "→ {'A': 'X', 'B': 'Y'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab77621-4214-4161-92fe-74395ef61f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],\n",
    "                        ['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr'],\n",
    "                        inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97797d62-2575-4d93-8256-50b185a08cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Initial')['Age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc6c971-4736-43e2-9734-32fd1e92da2c",
   "metadata": {},
   "source": [
    "## Filling NaN Ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7406b28b-43bb-468f-bcc2-a40e525f9a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assigning the NaN Values with the Ceil values of the mean ages\n",
    "# for i in range(len(data['Age'])):\n",
    "#     if data['Age'].isna().iloc[i]:  # Age가 NaN인 경우만 확인\n",
    "#         if data['Initial'].iloc[i] == 'Mr':\n",
    "#             data.loc[i, 'Age'] = 33\n",
    "#         elif data['Initial'].iloc[i] == 'Mrs':\n",
    "#             data.loc[i, 'Age'] = 36\n",
    "#         elif data['Initial'].iloc[i] == 'Master':\n",
    "#             data.loc[i, 'Age'] = 5\n",
    "#         elif data['Initial'].iloc[i] == 'Miss':\n",
    "#             data.loc[i, 'Age'] = 22\n",
    "#         elif data['Initial'].iloc[i] == 'Other':\n",
    "#             data.loc[i, 'Age'] = 46\n",
    "\n",
    "\n",
    "data.loc[(data.Age.isna())&(data.Initial=='Mr'),'Age']=33\n",
    "data.loc[(data.Age.isna())&(data.Initial=='Mrs'),'Age']=36\n",
    "data.loc[(data.Age.isna())&(data.Initial=='Master'),'Age']=5\n",
    "data.loc[(data.Age.isna())&(data.Initial=='Miss'),'Age']=22\n",
    "data.loc[(data.Age.isna())&(data.Initial=='Other'),'Age']=46"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069360e1-6083-412f-bae0-1c4f8f4baf16",
   "metadata": {},
   "source": [
    "=> 성능을 고려하면 벡터화된 코드가 훨씬 더 효율적이고 빠르기 때문에, 데이터의 크기가 크거나 성능이 중요한 경우에는 벡터화된 코드를 사용하는 것이 좋습니다.\n",
    "반복문을 사용하는 방법은 작은 데이터셋이나 간단한 처리에 적합하지만, 성능이 중요한 상황에서는 벡터화를 사용하는 것이 더 나은 선택입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac56fb9d-5d58-475a-9d7d-66e332dcd074",
   "metadata": {},
   "source": [
    "벡터화(Vectorization)\n",
    "- 데이터 처리에서 매우 중요한 개념으로, 데이터를 반복문 없이 한 번에 처리하는 방식  \n",
    "-  특히, pandas와 같은 라이브러리에서 제공하는 벡터화된 연산은 반복문을 사용하는 것보다 훨씬 효율적  \n",
    "- 벡터화는 성능 향상뿐만 아니라 코드의 간결성도 가져옴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256f44ce-bd34-486d-be2c-767a8547645d",
   "metadata": {},
   "source": [
    "✅isnull() vs isna() 차이점은?\n",
    "  \n",
    "isnull(): 원래부터 있었던 함수  \n",
    "isna(): 나중에 추가된 더 직관적인 이름  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b82197b-c8ae-4784-b70e-0c380a2cb161",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Age.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7088906b-6b81-4bc6-a8f8-6b67de250979",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Survived'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9618f6-326b-4bdf-8cef-9eb01f778915",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,2, figsize=(20,10))\n",
    "data[data['Survived']==0].Age.plot.hist(ax=ax[0], bins=20, edgecolor='black', color='red')\n",
    "ax[0].set_title('Survived = 0')\n",
    "x = list(range(0,85,5))\n",
    "ax[0].set_xticks(x) # x축 구간\n",
    "\n",
    "data[data['Survived']==1].Age.plot.hist(ax=ax[1], bins=20, edgecolor='black', color='green')\n",
    "ax[1].set_title('Survived = 1')\n",
    "x2 = list(range(0,85,5))\n",
    "ax[1].set_xticks(x2) # x축 구간\n",
    "\n",
    "f.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35ce0e7-2901-4770-9157-3c077b40e1f6",
   "metadata": {},
   "source": [
    "Q. xticks 할 때 왜 range범위를 list()로 감싸는지?\n",
    "  \n",
    "range()는 이터레이터이기 때문에 인덱싱, 슬라이싱 등의 처리가 불가능  \n",
    "set_xticks() 같은 함수는 보통 리스트 형태를 요구하므로 list()로 변환하는 것이 일반적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef65ef55-7dc3-463a-9d44-3a4fc0c79f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='Pclass',y='Survived', col='Initial', data=data, kind=\"point\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d1a401-c765-4a53-9365-0d8937381f1c",
   "metadata": {},
   "source": [
    "🔍 인사이트  \n",
    "'여성 및 어린이 먼저' 정책은 계급에 관계없이 그대로 적용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d8fbab-39c5-458a-b0fb-e103070efd58",
   "metadata": {},
   "source": [
    "## Embarked--> Categorical Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d20cd33-7284-4080-97e2-89f66cb1fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab([data.Embarked,data.Pclass],[data.Sex,data.Survived],margins=True).style.background_gradient(cmap='summer_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cc306b-17de-4583-af53-a964fd584c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab([data.Embarked],[data.Survived],margins=True).style.background_gradient(cmap='summer_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c753ae-a5cb-4973-a62d-4e8316d7b90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='Embarked',y='Survived',data=data, kind='point')\n",
    "fig=plt.gcf() # plt.gcf()는 현재 활성화된 matplotlib의 그림 객체(figure)를 가져온다.\n",
    "# 이 객체는 그래프의 크기나 속성 등을 수정할 수 있게 해준다.\n",
    "fig.set_size_inches(5,3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9542fdd1-7beb-4bec-9440-f48bb7871de1",
   "metadata": {},
   "source": [
    "🔍생존 수로만 보면 S 항구가 가장 많았지만,  \n",
    "비율로 보니 C 항구가 생존 확률이 높고 S 항구가 생존 확률이 가장 낮다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe49b19f-8424-4dcb-90ca-4a5e7feb34c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(2,2,figsize=(20,15))\n",
    "sns.countplot(x='Embarked',data=data,ax=ax[0,0])\n",
    "ax[0,0].set_title('Numbers Of Passengers Boarded')\n",
    "sns.countplot(x='Embarked',hue='Sex',data=data,ax=ax[0,1])\n",
    "ax[0,1].set_title('Male-Female Split for Embarked')\n",
    "sns.countplot(x='Embarked',hue='Survived',data=data,ax=ax[1,0])\n",
    "ax[1,0].set_title('Embarked vs Survived')\n",
    "sns.countplot(x='Embarked',hue='Pclass',data=data,ax=ax[1,1])\n",
    "ax[1,1].set_title('Embarked vs Pclass')\n",
    "\n",
    "f.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.2,hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2814af79-aa26-4694-b46f-f66e003831c7",
   "metadata": {},
   "source": [
    "- wspace → 서브플롯 사이의 가로 간격 (width space)  \n",
    "값이 클수록 그래프들 사이의 가로 간격이 넓어집니다.\n",
    "  \n",
    "- hspace → 서브플롯 사이의 세로 간격 (height space)  \n",
    "값이 클수록 그래프들 사이의 세로 간격이 넓어집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11529ed-81db-4d40-8063-d6c4f57178a2",
   "metadata": {},
   "source": [
    "📌 Observations (관찰 내용)  \n",
    "S 항구에서 가장 많은 승객이 탑승했으며, 이들 중 대다수가 3등급(Pclass3) 승객이었다.\n",
    "\n",
    "C 항구에서 탑승한 승객들은 상대적으로 생존율이 높았다.\n",
    "→ 이는 1등급과 2등급 승객들이 구조된 경우가 많았기 때문일 수 있다.\n",
    "\n",
    "S 항구는 부유한 사람들이 많이 탑승한 항구처럼 보인다.\n",
    "→ 그럼에도 불구하고 생존율은 낮았는데, 이는 3등급 승객의 약 81%가 생존하지 못했기 때문이다.\n",
    "\n",
    "Q 항구에서는 **승객의 약 95%가 3등급(Pclass3)**이었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a529ac17-b1be-48d7-9974-8e24dadd7e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='Pclass',y='Survived',hue='Sex',col='Embarked',data=data, kind='point')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02ea0cf-695c-4b85-9851-7bb0146e6e76",
   "metadata": {},
   "source": [
    "📌 Observations (관찰 내용)  \n",
    "1등급(Pclass1) 및 2등급(Pclass2) 여성의 생존 확률은 거의 1에 가까우며, 이는 등급과 관계없이 여성이라는 점이 큰 영향을 미쳤음을 보여준다.\n",
    "\n",
    "S 항구에서 출발한 3등급 승객(Pclass3) 은 매우 불운했으며,\n",
    "→ 특히 남성과 여성 모두의 생존율이 매우 낮았다.  \n",
    "→ 이는 \"돈이 생존을 좌우했다(Money Matters)\"는 점을 시사한다.\n",
    "\n",
    "Q 항구는 남성들에게 가장 불운한 항구로 보인다.\n",
    "→ 거의 모든 남성 승객이 3등급 승객이었고, 생존률도 낮았다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee762f5-7fde-4484-bc90-e4bc22cb7a50",
   "metadata": {},
   "source": [
    "## Filling Embarked NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd72162e-9f49-4533-9051-c4037d785ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Embarked'].fillna('S',inplace=True)\n",
    "# 가장 많은 승객이 탑승한 S 항구(Port S) 로 대체함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55afe02-37bb-4081-8ba8-76b60f57205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Embarked.isnull().any()# Finally No NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75ec93d-d5f5-4faf-a4ce-bc0f08de4dc9",
   "metadata": {},
   "source": [
    "## SibSip-->Discrete Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a67b1f-a8bb-4b1d-a807-b5a3b14a5dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab([data.SibSp],data.Survived).style.background_gradient(cmap='summer_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a289cf97-a888-4d74-935a-790d7280ae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "sns.barplot(x='SibSp', y='Survived', data=data, ax=ax[0])\n",
    "ax[0].set_title('SibSp vs Survived')\n",
    "\n",
    "sns.catplot(x='SibSp', y='Survived', data=data, kind='point')\n",
    "ax[1].set_title('SibSp vs Survived')\n",
    "\n",
    "# plt.close(2) 이걸 하면 catplot 그래프 출력이 안 됨\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddb348d-7f45-4f81-98b9-6be31bb63977",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data.SibSp,data.Pclass).style.background_gradient(cmap='summer_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8203f84d-746a-4087-b340-fd96cc0aee2f",
   "metadata": {},
   "source": [
    "📌 Observations (관찰 내용)  \n",
    "- 형제자매의 수가 증가함에 따라 생존율은 대체로 감소하는 경향을 보인다.\n",
    "놀랍게도 형제자매가 5명에서 8명인 가족의 생존율은 희박하다.\n",
    "그 이유는 아마도 **Pclass** 때문일 수 있다.\n",
    "- 교차표를 보면, **SibSp**가 4 이상의 사람들은 모두 **Pclass 3**에 속한 승객들이다.\n",
    "그래서 Pclass 3에 속한 대가족들이 대부분 사망했다는 사실은 명백하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc31e82-da94-42af-bbf4-376c81492ab0",
   "metadata": {},
   "source": [
    "## Parch\n",
    "#### 함께 탑승한 부모 또는 자녀 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe8a9d7-2106-415e-844c-eac8029cb3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data.Parch,data.Pclass).style.background_gradient(cmap='summer_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55485fde-17b6-4e1b-871b-6acc0b52641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(20,8))\n",
    "sns.barplot(x='Parch',y='Survived',data=data,ax=ax[0])\n",
    "ax[0].set_title('Parch vs Survived')\n",
    "\n",
    "sns.catplot(x='Parch',y='Survived',data=data,ax=ax[1],kind='point')\n",
    "ax[1].set_title('Parch vs Survived')\n",
    "\n",
    "f.tight_layout()\n",
    "# plt.close(2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b17da6-22e1-4fd6-8efd-9d963c2f1fa7",
   "metadata": {},
   "source": [
    "📌 Observations (관찰 내용)\n",
    "  \n",
    "부모와 함께 승선한 승객들은 생존 가능성이 더 높다.  \n",
    "그러나 부모의 수가 증가할수록 생존 가능성은 감소한다.  \n",
    "  \n",
    "부모가 1~3명 있는 경우 생존 확률이 높다.  \n",
    "반면, 혼자 있는 경우에는 생존 가능성이 낮고, 4명 이상의 부모와 함께 있는 경우에는 생존 확률이 더욱 감소한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006277fe-2bbf-4e4c-a9e0-8f17a7535cb5",
   "metadata": {},
   "source": [
    "## Fare--> Continous Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfccd05a-0a16-42c6-8ae1-7ca15435c0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Highest Fare was: ',data['Fare'].max(),)\n",
    "print('Lowest Fare was: ',data['Fare'].min())\n",
    "print('Average Fare was: ',round(data['Fare'].mean(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845beb5e-4526-455c-972e-cf2007b69619",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,3,figsize=(20,8))\n",
    "sns.distplot(data[data['Pclass']==1].Fare,ax=ax[0])\n",
    "ax[0].set_title('Fares in Pclass 1')\n",
    "\n",
    "sns.distplot(data[data['Pclass']==2].Fare,ax=ax[1])\n",
    "ax[1].set_title('Fares in Pclass 2')\n",
    "\n",
    "sns.distplot(data[data['Pclass']==3].Fare,ax=ax[2])\n",
    "ax[2].set_title('Fares in Pclass 3')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab44de4-a431-49ef-81ee-fedfee99e7bb",
   "metadata": {},
   "source": [
    "### 📌 **관찰 내용**:\n",
    "- **Fare Distribution**: **Pclass1** 승객들의 요금 분포가 매우 넓고, 이 분포는 계급이 낮아질수록 감소한다.  \n",
    "요금은 연속적인 값이기 때문에 **Binning**을 사용해 이를 이산적인 값으로 변환할 수 있다.  \n",
    "  \n",
    "### **모든 특성에 대한 핵심 관찰**:\n",
    "\n",
    "- **Sex**: 여성의 생존 확률이 남성에 비해 높다.\n",
    "  \n",
    "- **Pclass**: 1등석 승객이 생존 확률이 더 높은 경향이 있다.  \n",
    "**Pclass3**의 생존율은 매우 낮다.  \n",
    "여성의 경우 **Pclass1**에서 생존 확률이 거의 1에 가까우며, **Pclass2**에서도 생존 확률이 높다.  \n",
    "돈이 중요한 역할을 한다!\n",
    "  \n",
    "- **Age**: 5-10세 미만의 어린이는 높은 생존 확률을 보였다. 15세에서 35세 사이의 승객은 많은 수가 사망했다. \n",
    "  \n",
    "- **Embarked**: **C**에서 승객들의 생존 확률이 더 높아 보인다. 이는 **Pclass1** 승객의 대부분이 **S**에서 탔음에도 불구하고 그렇다. **Q** 항구에서 승객들은 대부분 **Pclass3**에 속했다.\n",
    "  \n",
    "- **Parch + SibSp**: 1-2명의 형제자매나 배우자, 또는 1-3명의 부모가 함께 승선한 경우 생존 확률이 더 높다.\n",
    "  반면, 혼자 있거나 대가족을 동반한 경우 생존 확률이 낮다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755781d6-68de-4184-b338-04fe2b05d013",
   "metadata": {},
   "source": [
    "연속적인 값을 Binning을 사용해 이산적인 값으로 변환한다는 점을 예시로 이해해보려 찾아보았다.\n",
    "  \n",
    "예시)  \n",
    "요금(Fare) 값이 10, 20, 35, 50, 100 등으로 매우 다양한 경우, Binning을 사용해 0-50, 50-100, 100 이상으로 나누면  \n",
    "분석할 때 더 명확한 경향을 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e153fd10-5992-47b6-9fe0-5a0da992a178",
   "metadata": {},
   "source": [
    "## Correlation Between The Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2d65b1-33f2-47f5-a1e8-63cdc68d0153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dae28b-2694-4db3-a0c6-f4ba1e6dd414",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data = data.select_dtypes(include=['number']) # corr()할 때 object형도 있으므로 error 발생\n",
    "\n",
    "sns.heatmap(numeric_data.corr(),annot=True,cmap='RdYlGn',linewidths=0.2) # annot=True 상관계수를 표시\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(10,8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d57593-4dda-4f51-9c24-c10d3ae7815b",
   "metadata": {},
   "source": [
    "🔍 상관 행렬(Heatmap) 해석  \n",
    "우선 주목할 점은, 상관 행렬은 숫자형 특성(numeric features)만 비교한다는 것이다.  \n",
    "알파벳이나 문자열은 수치적으로 상관 관계를 계산할 수 없기 때문이다.  \n",
    "  \n",
    "상관 관계를 이해하기 전에, 먼저 상관 관계가 무엇인지 짚고 넘어가겠다.  \n",
    "✅ 양의 상관관계 (Positive Correlation)  \n",
    "특성 A가 증가할 때 특성 B도 증가한다면, 두 특성은 양의 상관관계에 있다고 본다.  \n",
    "값이 1이면 완벽한 양의 상관관계를 의미한다.  \n",
    "  \n",
    "❌ 음의 상관관계 (Negative Correlation)  \n",
    "특성 A가 증가할 때 특성 B는 감소한다면, 두 특성은 음의 상관관계에 있다고 본다.  \n",
    "값이 -1이면 완벽한 음의 상관관계를 의미한다.  \n",
    "\n",
    "\n",
    "📌 다중공선성(Multicollinearity)  \n",
    "만약 두 특성이 매우 높은 상관관계를 가진다면, 한 특성의 변화가 다른 특성의 변화에 거의 동일하게 반영된다는 의미다.  \n",
    "즉, 두 특성 모두 거의 동일한 정보를 담고 있으며, 정보의 다양성(분산)이 부족하다는 것을 나타낸다.  \n",
    "  \n",
    "이러한 현상을 **다중공선성(Multicollinearity)**이라고 한다.  \n",
    "두 특성이 거의 같은 정보를 포함하고 있기 때문에, 그중 하나는 중복된 것으로 간주되며, 모델 학습 시 제거하는 것이 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57f0a50-c01c-4735-a218-1e28179fd115",
   "metadata": {},
   "source": [
    "## Part2: Feature Engineering and Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b29ff8-7c1e-4204-b275-ab8c0f18fd6a",
   "metadata": {},
   "source": [
    "🔧 Feature Engineering(특성 공학)이란?  \n",
    "주어진 데이터셋에 여러 특성이 포함되어 있다고 해서, 그 모든 특성이 반드시 중요한 것은 아니다.  \n",
    "많은 특성들 중에는 중복되거나 불필요한 특성이 있을 수 있으며, 이런 특성들은 제거하는 것이 좋다.  \n",
    "  \n",
    "또한, 기존의 특성에서 새로운 특성을 추출하거나 만들어낼 수도 있다.   \n",
    "예를 들어, Name 특성에서 Initials(이니셜)과 같은 새로운 특성을 도출할 수 있다.  \n",
    "  \n",
    "Feature Engineering은 다음과 같은 작업을 포함한다:  \n",
    "\n",
    "- 중요하지 않은 특성 제거\n",
    "- 유의미한 새로운 특성 생성\n",
    "- 예측 모델링에 적합하도록 기존 특성 변환  \n",
    "  \n",
    "이제 어떤 새로운 특성을 만들 수 있고, 어떤 특성을 제거할 수 있을지 살펴보겠다.  \n",
    "또한 예측 모델링을 위해 현재 사용 중인 특성들을 더 적절한 형태로 변환할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6301afc1-0d0b-432f-955b-b49e1ce683da",
   "metadata": {},
   "source": [
    "## Age_band"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca9c354-30fa-4324-be90-636a5ed1ffe0",
   "metadata": {},
   "source": [
    "🔧 **Feature Engineering**이란?  \n",
    "데이터셋이 주어졌을 때, 모든 특성이 항상 중요한 것은 아니다.  \n",
    "중복되거나 불필요한 특성은 제거해야 하며,  \n",
    "다른 특성에서 정보를 추출하거나 관찰하여 새로운 특성을 생성할 수도 있다.  \n",
    "  \n",
    "예를 들어, Name(이름)특성에서 Initials(이니셜)이라는 새로운 특성을 추출하는 것이 그 예시이다.  \n",
    "  \n",
    "이제 불필요한 특성을 제거하고, 새로운 특성을 생성하거나,  \n",
    "기존의 특성들을 예측 모델링에 적합한 형태로 변환(transform)해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d6bf94-8c8f-4fd9-a7c2-642580ca9b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector화\n",
    "data['Age_band']=0\n",
    "data.loc[data['Age']<=16,'Age_band']=0\n",
    "data.loc[(data['Age']>16)&(data['Age']<=32),'Age_band']=1\n",
    "data.loc[(data['Age']>32)&(data['Age']<=48),'Age_band']=2\n",
    "data.loc[(data['Age']>48)&(data['Age']<=64),'Age_band']=3\n",
    "data.loc[data['Age']>64,'Age_band']=4\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe0f21c-963a-45f9-a1f6-de951cad2539",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age_band'].value_counts().to_frame().style.background_gradient(cmap='summer')\n",
    "#checking the number of passenegers in each band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd54049-d1ec-431a-b8a7-dde46baa9674",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='Age_band',y='Survived',data=data,col='Pclass',kind='point')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d4cc77-ffbb-4e0f-9f3b-75d6c116967a",
   "metadata": {},
   "source": [
    "### Family_Size와 Alone\n",
    "\n",
    "이제 **Family_Size**와 **Alone**이라는 새로운 특성을 생성해서 분석할 수 있다.  \n",
    "**Family_Size**는 **Parch**와 **SibSp**의 합으로, 승객의 가족 크기를 나타낸다.  \n",
    "이 값을 통해 승객의 가족 크기와 생존율 간의 관계를 파악할 수 있다.  \n",
    "**Alone**은 승객이 혼자 탑승했는지 여부를 나타내는 특성으로, 승객이 혼자인지 아닌지를 확인하는 데 사용할 수 있다.\n",
    "\n",
    "이 특성들을 사용하면 승객이 가족과 함께 탑승했을 때 생존율에 어떤 영향을 미치는지 분석할 수 있다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b133ba89-d71c-4eae-b4ec-8d89d65eb565",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Family_Size']=0\n",
    "data['Family_Size']=data['Parch']+data['SibSp'] # family size\n",
    "data['Alone']=0\n",
    "data.loc[data.Family_Size==0,'Alone']=1 # Alone\n",
    "\n",
    "f,ax=plt.subplots(1,2,figsize=(18,6))\n",
    "sns.catplot(x='Family_Size',y='Survived',data=data,ax=ax[0],kind='point')\n",
    "ax[0].set_title('Family_Size vs Survived')\n",
    "\n",
    "sns.catplot(x='Alone',y='Survived',data=data,ax=ax[1],kind='point')\n",
    "ax[1].set_title('Alone vs Survived')\n",
    "\n",
    "# plt.close(2)\n",
    "# plt.close(3)\n",
    "f.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a70021-a98c-4049-8c87-361bffacf1a1",
   "metadata": {},
   "source": [
    "### Family_Size\n",
    "\n",
    "**Family_Size**가 0이면 승객이 혼자 있다는 뜻이다.  \n",
    "명확하게도, 혼자 있거나 **Family_Size = 0**일 경우 생존 확률이 매우 낮다.  \n",
    "가족 크기가 4명 이상인 경우에도 생존 확률이 낮아진다.  \n",
    "이 특성은 모델에서 중요한 역할을 할 수 있을 것 같다. 좀 더 자세히 분석해보자.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804878eb-e4bb-490b-8fab-9b435afeb367",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='Alone',y='Survived',data=data,hue='Sex',col='Pclass',kind='point')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1b17eb-ebab-484c-adcf-3175444410fd",
   "metadata": {},
   "source": [
    "혼자 있는 것이 **Sex**나 **Pclass**와 상관없이 해롭다는 것을 알 수 있다.\n",
    "- 혼자 있으면 성별이나 PClass 상관없이 왜 해로운지 모르겠다. 생존율이 높은데..?\n",
    "\n",
    "  \n",
    "단, **Pclass 3**에서는 혼자 있는 여성의 생존 확률이 가족과 함께 있는 여성보다 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aa90ad-1505-4465-a0e1-d76af44fed58",
   "metadata": {},
   "source": [
    "## Fare_Range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fc73e4-74c4-448f-bcc5-1b9275d9ba93",
   "metadata": {},
   "source": [
    "요금(Fare)도 연속적인 특성이기 때문에, 이를 순서형 값(Ordinal Value)으로 변환해야 한다.  \n",
    "이를 위해 `pandas.qcut`을 사용할 것이다.\n",
    "\n",
    "qcut은 우리가 지정한 개수의 구간(빈)으로 값을 나눈다.  \n",
    "예를 들어, 5개의 빈을 지정하면, qcut은 값을 균등하게 분할하여 5개의 구간 또는 값 범위로 나눈다.\n",
    "\n",
    "이 방식은 연속적인 데이터를 구간별로 나누어 모델에 적용할 수 있는 형태로 변환할 수 있게 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894f5ebf-040b-4cab-aaf3-e375b4af9ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Fare'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bac2d06-d2db-4b17-b54e-c6c38f184089",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Fare_Range'] = pd.qcut(data['Fare'],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b968faf2-fd67-4cf0-a9d0-61eb9b560a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Fare_Range'].value_counts()\n",
    "# qcut()은 균등하게 데이터가 들어가도록 구간을 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be57fa61-53f8-4e91-ae52-5bc1264a9bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['Fare_Range'])['Survived'].mean()\n",
    "# Fare_Range로 그룹화하여 생존율 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd127da-38f2-4685-bc06-ee95af09cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['Fare_Range'])['Survived'].mean().to_frame().style.background_gradient(cmap='summer_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a0d35-ad90-40ea-8dc1-54d463c3719a",
   "metadata": {},
   "source": [
    "Fare_Range는 현재 구간 형태로 되어 있어서 모델에 바로 사용할 수 없다.  \n",
    "그래서 각 구간을 숫자 값으로 변환해야 한다.  \n",
    "Age_Band처럼 구간을 특정 값으로 바꾼다.  \n",
    "예를 들어, 각 구간의 평균값이나 중간값을 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1f7bb9-4495-41c4-82cb-58ed19408500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범위를 명확하게 지정해주어야 한다.\n",
    "# 아래 코드는 원하는 결과를 얻지 못한다.\n",
    "\n",
    "# data['Fare_Cat'] = 0\n",
    "# data.loc[data['Fare'] <= 7.91, 'Fare_cat'] = 0\n",
    "# data.loc[data['Fare'] <= 14.454, 'Fare_cat'] = 1\n",
    "# data.loc[data['Fare'] <= 31.0, 'Fare_cat'] = 2\n",
    "# data.loc[data['Fare'] <= 512.329, 'Fare_cat'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57870813-d90d-40b0-b35b-7c31f9c2402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.catplot(x= 'Fare_cat', y='Survived',data=data,hue='Sex', kind='point')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4d5f79-893c-4916-aaf0-de0a56b58181",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Fare_cat']=0\n",
    "data.loc[data['Fare']<=7.91,'Fare_cat']=0\n",
    "data.loc[(data['Fare']>7.91)&(data['Fare']<=14.454),'Fare_cat']=1\n",
    "data.loc[(data['Fare']>14.454)&(data['Fare']<=31),'Fare_cat']=2\n",
    "data.loc[(data['Fare']>31)&(data['Fare']<=513),'Fare_cat']=3\n",
    "\n",
    "sns.catplot(x= 'Fare_cat', y='Survived',data=data,hue='Sex', kind='point')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbf9080-30aa-455b-adde-f5ab9c8b4013",
   "metadata": {},
   "source": [
    "성별에 따른 생존 확률  \n",
    "명확히 말하자면, Fare_cat이 증가할수록 생존 확률도 증가하는 경향이 있다.  \n",
    "이 특성은 모델링 과정에서 중요한 특성이 될 수 있다.  \n",
    "Sex와 함께 사용하면 모델 성능을 향상시킬 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3320ffbb-2aac-4bf1-b72c-82268ce0ef6c",
   "metadata": {},
   "source": [
    "## Converting String Values into Numeric\n",
    "### 문자열 값을 숫자로 변환하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96969b29-48e9-4edf-81b8-8f59da472cf1",
   "metadata": {},
   "source": [
    "기계 학습 모델에서는 문자열 값을 직접 사용할 수 없기 때문에, Sex, Embarked 등의 특성을 숫자 값으로 변환해야 한다.  \n",
    "이를 위해 가장 일반적으로 사용하는 방법은 라벨 인코딩(Label Encoding) 또는 원-핫 인코딩(One-Hot Encoding)이다.\n",
    "  \n",
    "- 라벨 인코딩(Label Encoding): 각 카테고리 값을 고유한 숫자로 변환하는 방식이다.\n",
    "- 원-핫 인코딩(One-Hot Encoding): 각 카테고리 값을 새로운 이진 특성(0 또는 1)을 만들어 표현하는 방식이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19347089-5b24-4fb3-934d-99b866a57957",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Sex'].replace(['male','female'],[0,1],inplace=True)\n",
    "data['Embarked'].replace(['S','C','Q'],[0,1,2],inplace=True)\n",
    "data['Initial'].replace(['Mr','Mrs','Miss','Master','Other'],[0,1,2,3,4],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fe4089-e58e-4269-a565-a63334e74f55",
   "metadata": {},
   "source": [
    "## Dropping UnNeeded Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1459a274-667a-4ab6-aa42-98f7d80bdad1",
   "metadata": {},
   "source": [
    "- Name → 이름 특성은 카테고리 값으로 변환할 수 없기 때문에 필요하지 않다.\n",
    "\n",
    "- Age → 나이는 Age_band 특성으로 대체할 수 있으므로 필요하지 않다.\n",
    "\n",
    "- Ticket → 티켓 번호는 랜덤한 문자열이기 때문에 카테고리화할 수 없다.\n",
    "\n",
    "- Fare → Fare_cat 특성이 있으므로 중복된 특성이다.\n",
    "\n",
    "- Cabin → NaN 값이 많고, 여러 객실을 가진 승객도 있기 때문에 분석에 도움이 되지 않는다.\n",
    "\n",
    "- Fare_Range → Fare_cat 특성이 있으므로 불필요하다.\n",
    "\n",
    "- PassengerId → 이 특성은 카테고리화할 수 없으므로 필요 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02511136-bbe6-48a6-8f2e-f75fbb988385",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Name','Age','Ticket','Fare','Cabin','Fare_Range','PassengerId'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fecb1f-d575-423b-a153-b27ab4072de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.corr(),annot=True,cmap='RdYlGn',linewidths=0.2,annot_kws={'size':20})\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(18,15)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ffcb5f-3335-4092-a13f-a5cf4be09f7f",
   "metadata": {},
   "source": [
    "SibSp and Family_Size, Famil_Size and Parch는 상관계수가 높다.  \n",
    "반면에 Alone and Family_Size는 상관계수가 낮다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d0a2f6-a63b-480d-bb7b-cd23ad080f35",
   "metadata": {},
   "source": [
    "## Part3: 예측 모델링\n",
    "우리는 EDA(탐색적 데이터 분석)에서 일부 통찰을 얻었지만, 이를 기반으로 승객이 생존할지 사망할지 정확히 예측할 수는 없다.  \n",
    "이제 우리는 몇 가지 훌륭한 분류 알고리즘을 사용하여 승객의 생존 여부를 예측할 것이다. 사용될 알고리즘은 다음과 같다:  \n",
    "\n",
    "- 로지스틱 회귀 (Logistic Regression)\n",
    "\n",
    "- 서포트 벡터 머신 (SVM) - 선형 및 비선형 (Radial)\n",
    "\n",
    "- 랜덤 포레스트 (Random Forest)\n",
    "\n",
    "- K-최근접 이웃 (K-Nearest Neighbours)\n",
    "\n",
    "- 나이브 베이즈 (Naive Bayes)\n",
    "\n",
    "- 결정 트리 (Decision Tree)\n",
    "\n",
    "- 로지스틱 회귀 (Logistic Regression)  \n",
    "  \n",
    "이 알고리즘들을 사용하여 승객이 생존할 확률을 예측하고 모델을 학습시킬 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698f14d7-c8ba-4731-9575-4fb24109e256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required ML packages\n",
    "from sklearn.linear_model import LogisticRegression #logistic regression\n",
    "from sklearn import svm #support vector Machine\n",
    "from sklearn.ensemble import RandomForestClassifier #Random Forest\n",
    "from sklearn.neighbors import KNeighborsClassifier #KNN\n",
    "from sklearn.naive_bayes import GaussianNB #Naive bayes\n",
    "from sklearn.tree import DecisionTreeClassifier #Decision Tree\n",
    "from sklearn.model_selection import train_test_split #training and testing data split\n",
    "from sklearn import metrics #accuracy measure\n",
    "from sklearn.metrics import confusion_matrix #for confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cc68c2-d0df-4898-86b4-2633f2572f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 훈련 세트와 테스트 세트로 나눈다. \n",
    "# test_size=0.3: 데이터의 30%를 테스트 세트로 사용하고, 나머지 70%를 훈련 세트로 사용\n",
    "# random_state=0: 랜덤 시드를 고정시켜 동일한 분할을 유지\n",
    "# stratify=data['Survived']: 'Survived' 값을 기준으로 데이터를 분할하여 생존자와 사망자의 비율을 유지\n",
    "train, test = train_test_split(data, test_size=0.3, random_state=0, stratify=data['Survived'])\n",
    "\n",
    "# 훈련 세트에서 독립 변수(features)만 추출 (Survived 컬럼을 제외한 나머지 컬럼들)\n",
    "train_X = train[train.columns[1:]]\n",
    "# 훈련 세트에서 종속 변수(target)인 'Survived'만 추출\n",
    "train_Y = train[train.columns[:1]]\n",
    "\n",
    "# 테스트 세트에서 독립 변수(features)만 추출 (Survived 컬럼을 제외한 나머지 컬럼들)\n",
    "test_X = test[test.columns[1:]]\n",
    "# 테스트 세트에서 종속 변수(target)인 'Survived'만 추출\n",
    "test_Y = test[test.columns[:1]]\n",
    "\n",
    "# 전체 데이터에서 'Survived' 컬럼을 제외한 모든 특성을 추출 (X: 독립 변수들)\n",
    "X = data[data.columns[1:]]\n",
    "# 전체 데이터에서 'Survived' 컬럼만 추출 (Y: 종속 변수)\n",
    "Y = data['Survived']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55736d37-23c2-4ed9-a358-994b07bb7a7e",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2548516c-569f-47bf-927c-75c668f16450",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(train_X,train_Y)\n",
    "prediction1=model.predict(test_X)\n",
    "print('The accuracy of the Logistic Regression is',metrics.accuracy_score(prediction1,test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d12953-4e39-431e-921d-de43937fdb7f",
   "metadata": {},
   "source": [
    "### Support Vector Machines(Linear and radial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15adfe11-fd01-414b-8abc-2da891133c28",
   "metadata": {},
   "source": [
    "Linear Support Vector Machine(linear-SVM) 선형적으로 분리 가능한 경우에 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d69ec2-83be-40cb-95d1-e24de880e817",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=svm.SVC(kernel='linear',C=0.1,gamma=0.1)\n",
    "model.fit(train_X,train_Y)\n",
    "prediction2_1=model.predict(test_X)\n",
    "print('Accuracy for linear SVM is',metrics.accuracy_score(prediction2_1,test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ed2f0c-fe88-4df9-8770-a72433ea3eae",
   "metadata": {},
   "source": [
    "Radial Support Vector Machines(rbf-SVM)\n",
    "비선형 문제를 해결하는 데 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4f18df-40a4-41dc-b02a-7806c6d7bfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=svm.SVC(kernel='rbf',C=1,gamma=0.1)\n",
    "model.fit(train_X,train_Y)\n",
    "prediction2_2=model.predict(test_X)\n",
    "print('Accuracy for rbf SVM is ',metrics.accuracy_score(prediction2_2,test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c6061d-ad36-4fb0-b365-0859c196b731",
   "metadata": {},
   "source": [
    "### 차이점 정리\n",
    "#### 커널 종류\n",
    "\n",
    "- Linear SVM: kernel='linear'\n",
    "- RBF SVM: kernel='rbf'\n",
    "\n",
    "#### 기능\n",
    "\n",
    "- Linear SVM은 선형 분리 가능한 데이터에 적합.\n",
    "- RBF SVM은 비선형 데이터에 적합."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3182816-1b24-4ef4-adbb-8591c680f42a",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ae11b2-c52f-492e-92e9-fc8d396ddfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RandomForestClassifier(n_estimators=100)\n",
    "model.fit(train_X,train_Y)\n",
    "prediction3=model.predict(test_X)\n",
    "print('The accuracy of the Random Forests is',metrics.accuracy_score(prediction3,test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47749073-7e7c-4893-8c6a-899fadc1f115",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da627f3d-e031-4749-808f-500915f3a747",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=KNeighborsClassifier() \n",
    "model.fit(train_X,train_Y)\n",
    "prediction4=model.predict(test_X)\n",
    "print('The accuracy of the KNN is',metrics.accuracy_score(prediction4,test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb0e1eb-f4d8-4195-9355-270bfb359bd8",
   "metadata": {},
   "source": [
    "KNeighborsClassifier의 n_neighbors 값을 여러 개로 바꿔가면서 정확도를 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46bd1d9-729f-43cc-ac57-e284752944f9",
   "metadata": {},
   "source": [
    "```\n",
    "a_index=list(range(1,11))\n",
    "a=pd.Series()\n",
    "x=[0,1,2,3,4,5,6,7,8,9,10]\n",
    "for i in list(range(1,11)):\n",
    "    model=KNeighborsClassifier(n_neighbors=i) \n",
    "    model.fit(train_X,train_Y)\n",
    "    prediction=model.predict(test_X)\n",
    "    a=a.append(pd.Series(metrics.accuracy_score(prediction,test_Y)))\n",
    "plt.plot(a_index, a)\n",
    "plt.xticks(x)\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(12,6)\n",
    "plt.show()\n",
    "print('Accuracies for different values of n are:',a.values,'with the max value as ',a.values.max())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d60cea-991d-411a-9605-bda4b073f514",
   "metadata": {},
   "source": [
    "최근 pandas 버전에서 .append() 메서드가 삭제되었기 때문에 오류가 발생한다.  \n",
    "  \n",
    "🔧 해결 방법  \n",
    "Series.append() 대신 pd.concat()을 쓰면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8974a3-c2f3-403a-bdae-a0c3c9c5ad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append ->concat 바꾸면 출력 결과가 조금 다르게 나옴\n",
    "\n",
    "\n",
    "a_index = list(range(1, 11))  # 1부터 10까지\n",
    "a = pd.Series()               # 빈 시리즈 생성\n",
    "x = list(range(0, 11))        # x축 눈금\n",
    "\n",
    "for i in a_index:\n",
    "    model = KNeighborsClassifier(n_neighbors=i)\n",
    "    model.fit(train_X, train_Y)\n",
    "    prediction = model.predict(test_X)\n",
    "    \n",
    "    # 정확도 계산해서 시리즈에 추가\n",
    "    accuracy = metrics.accuracy_score(prediction, test_Y)\n",
    "    a = pd.concat([a, pd.Series([accuracy])])\n",
    "\n",
    "# 정확도 시각화\n",
    "plt.plot(a_index, a)\n",
    "plt.xticks(x)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12, 6)\n",
    "plt.show()\n",
    "\n",
    "# 결과 출력\n",
    "print(\"각 k값에 대한 정확도:\", a.values)\n",
    "print(\"최고 정확도:\", a.values.max(), \"최고 정확도를 낸 이웃 수(k):\", a_index[a.values.argmax()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae341ba4-984e-436a-96a3-ee0bf81eca65",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012e7c3d-7a85-4070-bf79-38882688903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=GaussianNB()\n",
    "model.fit(train_X,train_Y)\n",
    "prediction5=model.predict(test_X)\n",
    "print('The accuracy of the NaiveBayes is',metrics.accuracy_score(prediction5,test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5092f0b-2b71-42aa-9fc9-3b7106bd79a1",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac21d4b1-bd34-478a-9202-033d4a37d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=DecisionTreeClassifier()\n",
    "model.fit(train_X,train_Y)\n",
    "prediction6=model.predict(test_X)\n",
    "print('The accuracy of the Decision Tree is',metrics.accuracy_score(prediction6,test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d581a64-af14-464c-b144-99a743638b14",
   "metadata": {},
   "source": [
    "모델 정확도만으로는 강력한 분류기라고 할 수 없다.  \n",
    "모델이 학습 데이터로 학습하고 테스트 데이터로 테스트해서 정확도 90%를 얻었다고 해보자.  \n",
    "  \n",
    "이건 얼핏 보면 꽤 좋은 성능처럼 보이지만, 앞으로 들어올 새로운 테스트 데이터셋들에서도 계속 90%를 유지할 수 있을까?  \n",
    "정답은 아니다.  \n",
    "  \n",
    "왜냐면 모델이 어떤 데이터를 학습에 사용할지에 따라 결과가 달라질 수 있기 때문이다.  \n",
    "학습 데이터와 테스트 데이터가 바뀌면 정확도도 오르락내리락할 수 있다.  \n",
    "이런 걸 **모델 분산**(variance)이라고 한다.  \n",
    "  \n",
    "그럼 이걸 어떻게 해결할까?  \n",
    "바로 **교차 검증**(Cross Validation)을 사용한다.  \n",
    "  \n",
    "이 방법을 쓰면 데이터를 여러 번 나눠서 학습/테스트를 반복하고, 그 평균 성능을 보는 방식이다.  \n",
    "이렇게 하면 우연에 의한 성능 편차를 줄이고, 일반화된(generalized) 모델을 만들 수 있다.  \n",
    "  \n",
    "필요하면 Cross Validation 코드에 대해 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d17dc5-0bad-4112-a49c-56327de9bfa4",
   "metadata": {},
   "source": [
    "## 교차 검증 (Cross Validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a312ab8-c166-4335-bb5d-5a1a218663b1",
   "metadata": {},
   "source": [
    "많은 경우, 데이터가 불균형할 수 있다.\n",
    "예를 들어, 어떤 클래스(예: 생존한 사람)는 많고, 다른 클래스(예: 사망한 사람)는 적을 수 있다.\n",
    "\n",
    "그래서 알고리즘을 전체 데이터셋의 모든 데이터 인스턴스에 대해 학습하고 테스트하는 게 좋다.\n",
    "이렇게 하면 여러 번 측정한 정확도 평균을 구할 수 있고, 더 신뢰할 수 있는 모델 평가가 가능하다.\n",
    "\n",
    "💡 K-Fold 교차 검증이란?\n",
    "먼저 데이터셋을 **k개의 하위 셋(subsets)**으로 나눈다.\n",
    "\n",
    "예를 들어 k=5라면, 데이터를 5등분해서, 그중 1개는 테스트용, 나머지 4개는 학습용으로 사용한다.\n",
    "\n",
    "그런 다음, 테스트용 부분을 하나씩 바꿔가면서 총 5번 반복한다.\n",
    "매번 학습-테스트를 반복하면서 정확도나 에러율을 기록한다.\n",
    "\n",
    "마지막에는 5번의 정확도를 평균내서 모델의 성능을 평가한다.\n",
    "\n",
    "이게 바로 K-Fold 교차 검증이다.\n",
    "\n",
    "🤔 왜 교차 검증이 필요할까?\n",
    "어떤 데이터셋에서는 알고리즘이 underfit될 수 있고,\n",
    "다른 셋에서는 overfit될 수도 있다.\n",
    "\n",
    "즉, 학습 데이터가 바뀌면 성능도 변할 수 있다는 말이다.\n",
    "그래서 교차 검증을 통해 일반화된(generalized) 모델을 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6b6407-2661-4491-8d3e-0296104635be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle = True 로 해주어야 오류가 발생하지 않는다.\n",
    "# random_state를 설정해주었는데 default가 shuffle=False 라서 생긴 오류다.\n",
    "\n",
    "from sklearn.model_selection import KFold #for K-fold cross validation\n",
    "from sklearn.model_selection import cross_val_score #score evaluation\n",
    "from sklearn.model_selection import cross_val_predict #prediction\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True,random_state=22) # k=10, split the data into 10 equal parts\n",
    "mean=[]\n",
    "accuracy=[]\n",
    "std=[]\n",
    "classifiers=['Linear Svm','Radial Svm','Logistic Regression','KNN','Decision Tree','Naive Bayes','Random Forest']\n",
    "models=[svm.SVC(kernel='linear'),svm.SVC(kernel='rbf'),LogisticRegression(),KNeighborsClassifier(n_neighbors=9),DecisionTreeClassifier(),GaussianNB(),RandomForestClassifier(n_estimators=100)]\n",
    "for i in models:\n",
    "    model = i\n",
    "    cv_result = cross_val_score(model,X,Y, cv = kfold,scoring = \"accuracy\")\n",
    "    cv_result=cv_result\n",
    "    mean.append(cv_result.mean())\n",
    "    std.append(cv_result.std())\n",
    "    accuracy.append(cv_result)\n",
    "new_models_dataframe2=pd.DataFrame({'CV Mean(각 모델 정확도의 평균)':mean,'Std':std},index=classifiers)       \n",
    "new_models_dataframe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aa3926-8c2a-4bbd-a78f-14fbe7d1c6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(12,6))\n",
    "box=pd.DataFrame(accuracy,index=[classifiers])\n",
    "box.T.boxplot()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c00a7-9823-4d72-9c3f-313185ff5020",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_models_dataframe2['CV Mean'].plot.barh(width=0.8)\n",
    "plt.title('Average CV Mean Accuracy')\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(8,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ebc47d-108d-400a-959c-01cbd8ec1f2a",
   "metadata": {},
   "source": [
    "분류 정확도는 불균형 문제로 인해 때때로 오해를 불러일으킬 수 있다.  \n",
    "혼동 행렬을 사용하면 모델이 어디에서 잘못 예측했는지, 또는 어떤 클래스를 잘못 예측했는지를 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9f54c3-fcac-49a1-92fa-e93d437a8d39",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fa2f62-1263-4dd8-9e27-0b3e10cc3df1",
   "metadata": {},
   "source": [
    "True Positives (TP): 올바르게 예측된 긍정 클래스의 수\n",
    "\n",
    "True Negatives (TN): 올바르게 예측된 부정 클래스의 수\n",
    "\n",
    "False Positives (FP): 잘못 긍정 클래스로 예측한 부정 클래스의 수\n",
    "\n",
    "False Negatives (FN): 잘못 부정 클래스로 예측한 긍정 클래스의 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a83e717-588d-4c40-91f9-697b3d444411",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(3,3,figsize=(12,10))\n",
    "y_pred = cross_val_predict(svm.SVC(kernel='rbf'),X,Y,cv=10)\n",
    "sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[0,0],annot=True,fmt='2.0f')\n",
    "ax[0,0].set_title('Matrix for rbf-SVM')\n",
    "\n",
    "y_pred = cross_val_predict(svm.SVC(kernel='linear'),X,Y,cv=10)\n",
    "sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[0,1],annot=True,fmt='2.0f')\n",
    "ax[0,1].set_title('Matrix for Linear-SVM')\n",
    "\n",
    "y_pred = cross_val_predict(KNeighborsClassifier(n_neighbors=9),X,Y,cv=10)\n",
    "sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[0,2],annot=True,fmt='2.0f')\n",
    "ax[0,2].set_title('Matrix for KNN')\n",
    "\n",
    "y_pred = cross_val_predict(RandomForestClassifier(n_estimators=100),X,Y,cv=10)\n",
    "sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[1,0],annot=True,fmt='2.0f')\n",
    "ax[1,0].set_title('Matrix for Random-Forests')\n",
    "\n",
    "y_pred = cross_val_predict(LogisticRegression(),X,Y,cv=10)\n",
    "sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[1,1],annot=True,fmt='2.0f')\n",
    "ax[1,1].set_title('Matrix for Logistic Regression')\n",
    "\n",
    "y_pred = cross_val_predict(DecisionTreeClassifier(),X,Y,cv=10)\n",
    "sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[1,2],annot=True,fmt='2.0f')\n",
    "ax[1,2].set_title('Matrix for Decision Tree')\n",
    "\n",
    "y_pred = cross_val_predict(GaussianNB(),X,Y,cv=10)\n",
    "sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[2,0],annot=True,fmt='2.0f')\n",
    "ax[2,0].set_title('Matrix for Naive Bayes')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.2,wspace=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbb0166-89f2-49b0-99c6-462d69481200",
   "metadata": {},
   "source": [
    "Confusion Matrix 해석\n",
    "Confusion Matrix에서 왼쪽 대각선은 각 클래스에 대해 올바르게 예측된 수를 나타내고, 오른쪽 대각선은 잘못 예측된 수를 나타낸다. 예를 들어, rbf-SVM의 경우를 살펴보겠다:\n",
    "\n",
    "정확한 예측:\n",
    "\n",
    "사망자(Dead) 예측: 491명\n",
    "\n",
    "생존자(Survived) 예측: 247명\n",
    "\n",
    "평균 정확도: (491 + 247) / 891 = 82.8% (이전에서 계산한 것과 일치)\n",
    "\n",
    "오류:\n",
    "\n",
    "잘못 예측된 사망자: 58명을 생존자로 예측\n",
    "\n",
    "잘못 예측된 생존자: 95명을 사망자로 예측\n",
    "\n",
    "결론: rbf-SVM 모델은 사망자를 생존자로 잘못 예측하는 경우가 많고, 생존자를 사망자로 예측하는 경우도 존재하지만 상대적으로 사망자 예측에서 더 많은 오류가 발생한다.\n",
    "\n",
    "이렇게 각 모델의 confusion matrix를 보고 나서, 각 모델의 장단점을 비교할 수 있다. 예를 들어, rbf-SVM은 사망자 예측에서 잘 작동하는 반면, Naive Bayes는 생존자 예측에서 더 정확한 결과를 보일 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fa44d8-395d-42c6-a045-dea39e732f11",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 튜닝\n",
    "머신러닝 모델은 블랙박스처럼 동작하며, 이 모델은 기본적으로 몇 가지 하이퍼파라미터 값을 갖고 있다. 이 하이퍼파라미터들은 모델을 최적화하고 더 좋은 성능을 낼 수 있도록 조정할 수 있다. 예를 들어, SVM 모델에서는 C와 gamma 값을, 랜덤 포레스트에서는 나무의 개수(n_estimators)와 최대 깊이(max_depth) 등 여러 파라미터를 조정할 수 있다.\n",
    "\n",
    "하이퍼파라미터 튜닝의 목적은 알고리즘의 학습률을 조정하고, 모델의 성능을 최적화하는 것이다. 이를 통해 모델이 주어진 데이터셋에 대해 더 나은 예측을 할 수 있도록 만든다.\n",
    "\n",
    "주요 하이퍼파라미터 튜닝 방법:\n",
    "\n",
    "- Grid Search: 여러 하이퍼파라미터 값들을 지정하고, 그 값들을 조합해가며 최적의 파라미터를 찾는 방법\n",
    "- Random Search: 여러 파라미터 값들 중 랜덤하게 선택하여 최적의 값을 찾는 방법\n",
    "- Bayesian Optimization: 확률적 모델을 사용하여 최적의 하이퍼파라미터를 찾는 방법\n",
    "\n",
    "결론: SVM과 Random Forest와 같은 모델들은 하이퍼파라미터 튜닝을 통해 성능을 크게 개선할 수 있다. 튜닝을 통해 모델이 데이터를 더 잘 학습하고 예측할 수 있도록 도와준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b103273-1918-4ee8-aa02-1d49f804ed5c",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efadd41-4e82-469b-a05b-0f1a76066995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "C=[0.05,0.1,0.2,0.3,0.25,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "gamma=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "kernel=['rbf','linear']\n",
    "hyper={'kernel':kernel,'C':C,'gamma':gamma}\n",
    "gd=GridSearchCV(estimator=svm.SVC(),param_grid=hyper,verbose=True)\n",
    "gd.fit(X,Y)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899156f4-7cbe-4d97-beb7-e58d7b7a68ea",
   "metadata": {},
   "source": [
    "### 결론\n",
    "이 모델은 C=0.5와 gamma=0.1로 설정된 rbf 커널을 사용하는 서포트 벡터 머신(SVM) 모델을 사용하여 82.83%의 교차 검증 정확도를 기록했다.\n",
    "\n",
    "이 결과는 GridSearchCV를 통해 가장 성능이 좋은 하이퍼파라미터 조합을 찾은 후 나온 값이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93555d70-60c8-44de-a8cf-51f15e37a035",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7827145-7edf-4adf-a519-160f26e4267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators=range(100,1000,100)\n",
    "hyper={'n_estimators':n_estimators}\n",
    "gd=GridSearchCV(estimator=RandomForestClassifier(random_state=0),param_grid=hyper,verbose=True)\n",
    "gd.fit(X,Y)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b571ad7-b025-4c51-8cc2-abdef75b630b",
   "metadata": {},
   "source": [
    "### 결론\n",
    "이 RandomForestClassifier 모델은 900개의 트리로 학습하며, 81.71%의 교차 검증 정확도를 기록했다.\n",
    "\n",
    "모델의 하이퍼파라미터는 기본 값들을 대부분 사용하였고, 최적의 하이퍼파라미터 조합으로 학습되었음을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828a94fd-d9c8-4005-b9b4-137c52cb4fbf",
   "metadata": {},
   "source": [
    "## Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a575fc3-fe41-4484-9425-bcf7700ec2a1",
   "metadata": {},
   "source": [
    "**앙상블**(Ensembling)은 모델의 정확도나 성능을 향상시키는 좋은 방법이다.  \n",
    "간단히 말하면, 여러 개의 간단한 모델들을 결합하여 하나의 강력한 모델을 만드는 방식이다.\n",
    "  \n",
    "예를 들어, 우리가 전화기를 구매하고자 할 때, 여러 사람에게 다양한 파라미터를 기반으로 의견을 물어본다. 그런 후 다양한 의견을 종합하여 제품에 대한 강력한 판단을 내린다. 이것이 바로 앙상블 기법이다. 앙상블 기법은 모델의 안정성을 향상시킨다.\n",
    "  \n",
    "앙상블 기법은 여러 가지 방식으로 구현할 수 있다:\n",
    "  \n",
    "1. **투표 분류기(Voting Classifier)**: 여러 모델이 예측한 결과를 종합하여 최종 예측을 결정한다. 보통 다수결 원칙을 따르거나 확률 기반으로 투표를 진행한다.\n",
    "\n",
    "2. **배깅(Bagging)**: 여러 개의 모델을 독립적으로 학습시켜 예측을 통합하는 방식이다. 각 모델은 데이터를 부트스트래핑(복원 추출)하여 학습하고, 그 예측 결과를 평균 또는 다수결로 결합한다. 대표적인 알고리즘으로 **랜덤 포레스트(Random Forest)**가 있다.\n",
    "\n",
    "3. **부스팅(Boosting)**: 여러 개의 약한 학습자(weak learners)를 순차적으로 학습시켜 점진적으로 성능을 향상시키는 방법이다. 이전 모델의 오류를 다음 모델이 수정하도록 학습시키며, 대표적인 알고리즘으로 **Adaboost**, **Gradient Boosting**, **XGBoost** 등이 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3ff0d0-1365-45e3-bc49-bc85d2886916",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76293fd2-8145-4fa0-b450-8959de1b00bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "ensemble_lin_rbf=VotingClassifier(estimators=[('KNN',KNeighborsClassifier(n_neighbors=10)),\n",
    "                                              ('RBF',svm.SVC(probability=True,kernel='rbf',C=0.5,gamma=0.1)),\n",
    "                                              ('RFor',RandomForestClassifier(n_estimators=500,random_state=0)),\n",
    "                                              ('LR',LogisticRegression(C=0.05)),\n",
    "                                              ('DT',DecisionTreeClassifier(random_state=0)),\n",
    "                                              ('NB',GaussianNB()),\n",
    "                                              ('svm',svm.SVC(kernel='linear',probability=True))\n",
    "                                             ], \n",
    "                       voting='soft').fit(train_X,train_Y)\n",
    "print('The accuracy for ensembled model is:',ensemble_lin_rbf.score(test_X,test_Y))\n",
    "cross=cross_val_score(ensemble_lin_rbf,X,Y, cv = 10,scoring = \"accuracy\")\n",
    "print('The cross validated score is',cross.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c408beab-2019-4192-9ce0-3f4ddba020d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b3fd7a-e427-4fb4-93d6-073fd2edc03c",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be1cc7d-a3c0-456c-b079-0f852eab25c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "model=BaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=3),random_state=0,n_estimators=700)\n",
    "model.fit(train_X,train_Y)\n",
    "prediction=model.predict(test_X)\n",
    "print('The accuracy for bagged KNN is:',metrics.accuracy_score(prediction,test_Y))\n",
    "result=cross_val_score(model,X,Y,cv=10,scoring='accuracy')\n",
    "print('The cross validated score for bagged KNN is:',result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e4ed17-f014-4044-a113-ad13b34ec54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bagged DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5914c66b-9c02-4703-a16c-cc138cc2dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=BaggingClassifier(base_estimator=DecisionTreeClassifier(),random_state=0,n_estimators=100)\n",
    "model.fit(train_X,train_Y)\n",
    "prediction=model.predict(test_X)\n",
    "print('The accuracy for bagged Decision Tree is:',metrics.accuracy_score(prediction,test_Y))\n",
    "result=cross_val_score(model,X,Y,cv=10,scoring='accuracy')\n",
    "print('The cross validated score for bagged Decision Tree is:',result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e8ec55-ec51-44a1-93ca-b7ee6e1659bc",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed547219-dd7c-45ef-8482-21b664f1f1a9",
   "metadata": {},
   "source": [
    "AdaBoost(Adaptive Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8146b961-13ea-45da-9cf9-f6d9eebf1c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada=AdaBoostClassifier(n_estimators=200,random_state=0,learning_rate=0.1)\n",
    "result=cross_val_score(ada,X,Y,cv=10,scoring='accuracy')\n",
    "print('The cross validated score for AdaBoost is:',result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba8d86e-824f-4665-9910-e97f595e9bed",
   "metadata": {},
   "source": [
    "Stochastic Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dd810c-07df-4b06-b15e-84d0b10d18dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "grad=GradientBoostingClassifier(n_estimators=500,random_state=0,learning_rate=0.1)\n",
    "result=cross_val_score(grad,X,Y,cv=10,scoring='accuracy')\n",
    "print('The cross validated score for Gradient Boosting is:',result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17139c87-8e99-48ec-bc04-14b68a686646",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbe95ce-988b-499a-89a4-eeaccecaa0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xg\n",
    "xgboost=xg.XGBClassifier(n_estimators=900,learning_rate=0.1)\n",
    "result=cross_val_score(xgboost,X,Y,cv=10,scoring='accuracy')\n",
    "print('The cross validated score for XGBoost is:',result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995de758-ceff-4f0f-bb99-72c7eb369114",
   "metadata": {},
   "source": [
    "Hyper-Parameter Tuning for AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc155f-46e5-416c-889a-9c0007311ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators=list(range(100,1100,100))\n",
    "learn_rate=[0.05,0.1,0.2,0.3,0.25,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "hyper={'n_estimators':n_estimators,'learning_rate':learn_rate}\n",
    "gd=GridSearchCV(estimator=AdaBoostClassifier(),param_grid=hyper,verbose=True)\n",
    "gd.fit(X,Y)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a00fdf4-8f7f-4010-a685-a9ba0c8c4ce9",
   "metadata": {},
   "source": [
    "## Confusion Matrix for the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a38809-5f2b-4a2a-baad-01955f4ffbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada=AdaBoostClassifier(n_estimators=200,random_state=0,learning_rate=0.05)\n",
    "result=cross_val_predict(ada,X,Y,cv=10)\n",
    "sns.heatmap(confusion_matrix(Y,result),cmap='winter',annot=True,fmt='2.0f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9ba7f4-6d0a-4205-ad7d-a69bf418b6cd",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98244798-f9d7-4a4d-83bc-2a4d2c476fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(2,2,figsize=(15,12))\n",
    "model=RandomForestClassifier(n_estimators=500,random_state=0)\n",
    "model.fit(X,Y)\n",
    "pd.Series(model.feature_importances_,X.columns).sort_values(ascending=True).plot.barh(width=0.8,ax=ax[0,0])\n",
    "ax[0,0].set_title('Feature Importance in Random Forests')\n",
    "model=AdaBoostClassifier(n_estimators=200,learning_rate=0.05,random_state=0)\n",
    "model.fit(X,Y)\n",
    "pd.Series(model.feature_importances_,X.columns).sort_values(ascending=True).plot.barh(width=0.8,ax=ax[0,1],color='#ddff11')\n",
    "ax[0,1].set_title('Feature Importance in AdaBoost')\n",
    "model=GradientBoostingClassifier(n_estimators=500,learning_rate=0.1,random_state=0)\n",
    "model.fit(X,Y)\n",
    "pd.Series(model.feature_importances_,X.columns).sort_values(ascending=True).plot.barh(width=0.8,ax=ax[1,0],cmap='RdYlGn_r')\n",
    "ax[1,0].set_title('Feature Importance in Gradient Boosting')\n",
    "model=xg.XGBClassifier(n_estimators=900,learning_rate=0.1)\n",
    "model.fit(X,Y)\n",
    "pd.Series(model.feature_importances_,X.columns).sort_values(ascending=True).plot.barh(width=0.8,ax=ax[1,1],color='#FD0F00')\n",
    "ax[1,1].set_title('Feature Importance in XgBoost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b2e83a-6668-4219-bcdd-20a20cdf6a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
